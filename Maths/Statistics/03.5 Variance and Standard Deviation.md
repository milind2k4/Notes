Links: [[03 Deviation]]
___
# Variance & Standard Deviation
#important 

### Variance
Variance is denoted by $\ce{ var(x) or variance(x) or \sigma^{2} }$

#### Ungrouped Data
$$\sigma^{2} = \frac{ \sum (x_{i} - \bar{x})^{2} }{ n }$$
(we only take mean of the data)

Opening the square, we can wire the variance as,
$$\sigma^{2} = \frac{ \sum (x_{i})^{2} }{ n } - (\bar{x})^{2}$$

As $\sigma^{2} \geq 0$,
$$
\begin{split}
\frac{ \sum x_{i}^{2} }{ n } - \left( \frac{ \sum x_{i} }{ n } \right)^{2} &\geq 0 \\
\frac{ \sum x_{i}^{2} }{ n } &\geq \left( \frac{ \sum x_{i} }{ n } \right)^{2} \\

\end{split}
$$
#### Grouped Data or Continuous Frequency Distribution
$$\sigma^{2} = \frac{ \sum f_{i}(x_{i} - \bar{x})^{2} }{ \sum  f_{i} }$$
in continuous frequency distribution, we take the mean of class interval as $x_{i}$. 

Opening the square, this can be written as,
$$\sigma^{2} = \frac{ \sum f_{i}x_{i}^{2} }{ \sum f_{i} } - \bar{x}^{2}$$

### Standard Deviation
Standard deviation is the root of variance,
$$\sigma = \sqrt{ \frac{ \sum (x_{i} - \bar{x})^{2} }{ n } }$$
$$\sigma = \sqrt{ \frac{ \sum (x_{i})^{2} }{ n } - (\bar{x})^{2} }$$

For any data set, 
$$\sigma \leq \text{Range}$$

Proof.
![[Pasted image 20230610093627.png]]


### Some things to Note
$$\sum (x_{i} - \bar{x}) = 0$$

Let 
$$f(A) = \sum (x_{i}- A)^{2}$$
which is the sum of squares of deviation of data points form a given number A.
Note that its value will change if we take a different A.

Opening the square,
$$
\begin{split}
f(A) &= \sum (x_{i} + A^{2} - 2x_{i}A) \\
&= nA^{2} - 2A\sum x_{i} + \sum x_{i}^{2} 
\end{split}
$$
which is a parabola upwards in variable A which will take its min value at vertex i.e. 
$$
\begin{split}
A &= \frac{-b}{2a} \\
&= \frac{ -2\left( \sum x_{i} \right) }{ 2n } \\
&= \frac{ \sum x_{i} }{ n }
\end{split}
$$
thus the sum of squared of deviations around a value A will be min when A is means of data set. 


#### Properties of Variance and Standard Deviation
1. If we add something to every element, the variance does not change. Thus, variance does not depend on Shifting of origin.
   $\\$
2. If we multiply each element with some constant, the variance is multiplied by that constant squared, and standard deviation will be multiplied by the mod of that number.

Thus, if
$$y_{i} = kx_{i} + c$$
then,
$$\sigma_{y}^{2} = k^{2}\sigma_{x}^{2}$$
$$\sigma_{y} = |k|\sigma_{x}$$

Therefore, variance and standard deviation are independent of shifting of origin but dependent on scale.
